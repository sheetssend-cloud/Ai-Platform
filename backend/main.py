
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os

try:
    import openai
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if HAS_OPENAI and OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY

app = FastAPI(title="Multi-Agent AI Brainstorming API")

# CORS for Next.js
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class AskPayload(BaseModel):
    question: str
    provider: str | None = "mock"

@app.get("/models")
def list_models():
    return {
        "current": "openai" if OPENAI_API_KEY else "mock",
        "available_models": [
            {
                "id": "openai",
                "name": "üß† GPT-5 (OpenAI)",
                "description": "‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡πâ‡∏î",
                "speed": "‚ö°‚ö° ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á-‡πÄ‡∏£‡πá‡∏ß",
                "cost": "$0.03"
            },
            {
                "id": "gemini",
                "name": "üåê Gemini 2.5 (Google)",
                "description": "‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏î‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå",
                "speed": "‚ö°‚ö°‚ö° ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å",
                "cost": "$0.02"
            },
            {
                "id": "claude",
                "name": "ü§ñ Claude 3 (Anthropic)",
                "description": "‡πÄ‡∏Å‡πà‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£",
                "speed": "‚ö°‚ö° ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á",
                "cost": "$0.025"
            },
            {
                "id": "mock",
                "name": "üß™ Mock LLM (‡∏ó‡∏î‡∏™‡∏≠‡∏ö)",
                "description": "‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢",
                "speed": "‚ö°‚ö°‚ö°‚ö° ‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
                "cost": "$0.00"
            }
        ]
    }

def mock_response(q: str):
    return {
        "plan": f"üìë ‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {q}\n- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏à‡∏ó‡∏¢‡πå\n- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢\n- ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô",
        "research": f"üîé ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö '{q}' ‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö",
        "analysis": "üìä ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢ ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á ‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™ ‡πÅ‡∏•‡∏∞‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ",
        "critique": "üß™ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞",
        "final": "üß† ‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"
    }

@app.post("/ask")
async def ask_ai(payload: AskPayload):
    q = payload.question
    provider = (payload.provider or "mock").lower()

    if provider == "openai" and HAS_OPENAI and OPENAI_API_KEY:
        try:
            # Use Chat Completions; fall back to mock if SDK not available
            completion = await openai.ChatCompletion.acreate(
                model=os.getenv("OPENAI_MODEL", "gpt-4o"),
                messages=[
                    {"role": "system", "content": "You are a team of AI agents brainstorming in Thai."},
                    {"role": "user", "content": q}
                ]
            )
            answer = completion.choices[0].message["content"]
            return {
                "plan": "üìë ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å GPT:\n" + answer,
                "research": "üîé ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡πâ‡∏ô‡∏Ñ‡∏ß‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\n" + answer,
                "analysis": "üìä ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å\n" + answer,
                "critique": "üß™ ‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö\n" + answer,
                "final": "üß† ‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n" + answer,
            }
        except Exception as e:
            # Fallback to mock on error
            return mock_response(q + f"\n(‚ö†Ô∏è openai error: {e})")

    # For gemini/claude in this scaffold, we fallback to mock
    if provider in {"gemini", "claude"}:
        return mock_response(q + "\n(‚ÑπÔ∏è ‡πÄ‡∏î‡πÇ‡∏°‡πà: ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå backend ‡∏ô‡∏µ‡πâ)")

    return mock_response(q)

@app.get("/")
def root():
    return {"ok": True, "service": "multiagent-backend"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
